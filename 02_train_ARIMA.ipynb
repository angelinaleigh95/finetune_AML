{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de57556d-a92b-4b61-9c7f-9a96a76880e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ARIMA training\n",
    "- This is an auto-generated notebook.\n",
    "- To reproduce these results, attach this notebook to a cluster with runtime version **14.3.x-cpu-ml-scala2.12**, and rerun it.\n",
    "- Compare trials in the [MLflow experiment](#mlflow/experiments/4049278270723788).\n",
    "- Clone this notebook into your project folder by selecting **File > Clone** in the notebook toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "501fc21f-8e8c-474f-a12c-71f5a236f09f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import databricks.automl_runtime\n",
    "\n",
    "target_col = \"High\"\n",
    "time_col = \"Date\"\n",
    "unit = \"day\"\n",
    "\n",
    "horizon = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65c3ad6c-a20f-4a19-8d41-b2c257dea43d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfc1a75c-fbae-4715-922f-4ff930bd586b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# Create temp directory to download input data from MLflow\n",
    "input_temp_dir = os.path.join(os.environ[\"SPARK_LOCAL_DIRS\"], \"tmp\", str(uuid.uuid4())[:8])\n",
    "os.makedirs(input_temp_dir)\n",
    "\n",
    "# Download the artifact and read it into a pandas DataFrame\n",
    "input_data_path = mlflow.artifacts.download_artifacts(run_id=\"8a3c658e627d4cd8a2f91b7d79eb95cb\", artifact_path=\"data\", dst_path=input_temp_dir)\n",
    "\n",
    "input_file_path = os.path.join(input_data_path, \"training_data\")\n",
    "input_file_path = \"file://\" + input_file_path\n",
    "df_loaded = ps.from_pandas(pd.read_parquet(input_file_path))\n",
    "\n",
    "# Preview data\n",
    "display(df_loaded.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91c262ab-bdad-41b4-9589-b7ebfd4d74ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Aggregate data by `time_col`\n",
    "Group the data by `time_col`, and take average if there are multiple `target_col` values in the same group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e738b488-32e2-464d-a8d9-f608a36df256",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group_cols = [time_col]\n",
    "df_aggregated = df_loaded \\\n",
    "  .groupby(group_cols) \\\n",
    "  .agg(y=(target_col, \"avg\")) \\\n",
    "  .reset_index()\n",
    "\n",
    "display(df_aggregated.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "283a8ee2-0732-4409-97ec-a75e66d80695",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Train ARIMA model\n",
    "- Log relevant metrics to MLflow to track runs\n",
    "- All the runs are logged under [this MLflow experiment](#mlflow/experiments/4049278270723788)\n",
    "- Change the model parameters and re-run the training cell to log a different trial to the MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b468c0f4-bd0b-4883-a6cb-e13a9688db15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the search space of seasonal period m\n",
    "seasonal_periods = [1, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "181c7465-cb33-4315-b232-d6235cae1ea3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4b240e2-fa06-48dd-b9f2-8d47133e0370",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result_columns = [\"pickled_model\", \"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "\n",
    "def arima_training(history_pd):\n",
    "  from databricks.automl_runtime.forecast.pmdarima.training import ArimaEstimator\n",
    "\n",
    "  arima_estim = ArimaEstimator(horizon=horizon,\n",
    "                               frequency_unit=unit,\n",
    "                               metric=\"smape\",\n",
    "                               seasonal_periods=seasonal_periods,\n",
    "                               num_folds=20)\n",
    "\n",
    "  results_pd = arima_estim.fit(history_pd)\n",
    " \n",
    "  return results_pd[result_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b25e06d3-88e9-4cd9-8a5e-548b32d36287",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks.automl_runtime.forecast.pmdarima.model import ArimaModel, mlflow_arima_log_model\n",
    "\n",
    "with mlflow.start_run(experiment_id=\"4049278270723788\", run_name=\"Arima\") as mlflow_run:\n",
    "  mlflow.set_tag(\"estimator_name\", \"ARIMA\")\n",
    "\n",
    "  df_aggregated = df_aggregated.rename(columns={time_col: \"ds\"})\n",
    "\n",
    "  arima_results = arima_training(df_aggregated.to_pandas())\n",
    "    \n",
    "  # Log metrics to mlflow\n",
    "  metric_names = [\"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "  avg_metrics = arima_results[metric_names].mean().to_frame(name=\"mean_metrics\").reset_index()\n",
    "  avg_metrics[\"index\"] = \"val_\" + avg_metrics[\"index\"].astype(str)\n",
    "  avg_metrics.set_index(\"index\", inplace=True)\n",
    "  mlflow.log_metrics(avg_metrics.to_dict()[\"mean_metrics\"])\n",
    "\n",
    "  # Save the model to mlflow\n",
    "  pickled_model = arima_results[\"pickled_model\"].to_list()[0]\n",
    "  arima_model = ArimaModel(pickled_model, horizon, unit, df_aggregated[\"ds\"].min(), df_aggregated[\"ds\"].max(), time_col)\n",
    "\n",
    "  # Generate sample input dataframe\n",
    "  sample_input = df_loaded.tail(5).to_pandas()\n",
    "  sample_input[time_col] = pd.to_datetime(sample_input[time_col])\n",
    "  sample_input.drop(columns=[target_col], inplace=True)\n",
    "\n",
    "  mlflow_arima_log_model(arima_model, sample_input=sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53afab00-851e-483b-8013-48d7f33aae1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "621f16bb-007c-454c-b339-ca62fdaf51db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analyze the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6e3812d-a51d-46ee-bd4e-ff5fd7f54268",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "run_id = mlflow_run.info.run_id\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8e27e92-5138-44c1-9c81-06a23bdef8b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "future_df = loaded_model._model_impl.python_model.make_future_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08f6cfe0-be2f-424c-8a3f-59966e222953",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict future with the default horizon\n",
    "forecast_pd = loaded_model._model_impl.python_model.predict_timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5673e98-27e2-457b-845d-c868a0bf72ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.automl_runtime.forecast.pmdarima.utils import plot\n",
    "\n",
    "history_pd = df_aggregated.to_pandas()\n",
    "# When visualizing, we ignore the first d (differencing order) points of the prediction results\n",
    "# because it is impossible for ARIMA to predict the first d values\n",
    "d = loaded_model._model_impl.python_model.model().order[1]\n",
    "fig = plot(history_pd[d:], forecast_pd[d:])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ac561ae-f1e6-44d5-98a9-557fbe34f667",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Show the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "177375a6-217d-4364-816a-5f9297af1ea5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predict_cols = [\"ds\", \"yhat\"]\n",
    "forecast_pd = forecast_pd.reset_index()\n",
    "display(forecast_pd[predict_cols].tail(horizon))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_train_ARIMA",
   "widgets": {}
  },
  "name": "ARIMA-7c40f7fb6c9cdd036a5e7edeb9685e09"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
